{"cells":[{"metadata":{},"cell_type":"markdown","source":"# NOTEBOOK Kaggle Cassava Competion\n## I. Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nfrom functools import partial\nfrom PIL import Image\nimport shutil ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## II. Fonctions utilitaires"},{"metadata":{"trusted":true},"cell_type":"code","source":"def scheduler(epoch, lr):\n    if epoch < 40:\n        return lr\n    else:\n        return lr * tf.math.exp(-0.05)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_logs(all_logs):\n    for logs in all_logs:\n        losses = logs.history['loss']\n        val_losses = logs.history['val_loss']\n        plt.plot(list(range(len(losses))), losses, label=\"Train Loss\")\n        plt.plot(list(range(len(losses))), val_losses, label=\"Val Loss\")\n        plt.title(\"Evolution du loss\") \n    plt.show()\n\n    for logs in all_logs:\n        metric = logs.history['categorical_accuracy']\n        val_metric = logs.history['val_categorical_accuracy']\n        plt.plot(list(range(len(metric))), metric, label=\"Train Accuracy\")\n        plt.plot(list(range(len(metric))), val_metric, label=\"Train Accuracy\")\n        plt.title(\"Evolution de l'accuracy\") \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_predictions(model):\n    preds = []\n    origin = \"../input/cassava-leaf-disease-classification\"\n    # sample_sub = pd.read_csv(origin + '/train.csv')\n    sample_sub = pd.read_csv(origin + '/sample_submission.csv')\n\n    for image in sample_sub.image_id:\n        img = tf.keras.preprocessing.image.load_img(origin + '/test_images/' + image)\n        img = tf.keras.preprocessing.image.img_to_array(img)\n        img = tf.keras.preprocessing.image.smart_resize(img, (256, 256))\n        img = np.expand_dims(img, 0)\n        prediction = model.predict(img)\n        preds.append(np.argmax(prediction))\n\n    my_submission = pd.DataFrame({'image_id': sample_sub.image_id, 'label': preds})\n    my_submission.to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## III. Définition des modèles"},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_linear_model(train_dataset, val_dataset, opt, loss_func, epochs, batch_size):\n    model = keras.models.Sequential()\n\n    # model.add(keras.Input(shape=(*IMAGE_SIZE,3)))\n    \n    model.add(keras.layers.Flatten())\n\n    model.add(keras.layers.Dense(5, activation=keras.activations.softmax))\n\n    model.compile(optimizer=opt, loss=loss_func, metrics=keras.metrics.categorical_accuracy)\n\n    logs = model.fit(train_dataset, validation_data=val_dataset, epochs=epochs, batch_size=batch_size,\n                    steps_per_epoch=10, validation_steps=5,\n                     callbacks=[keras.callbacks.LearningRateScheduler(scheduler)])\n\n    model.summary()\n    model.save(\"convnet_aerial\")\n    return logs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_fully_connected(x, y, val_x, val_y, opt, loss_func, epochs, batch_size):\n    model = keras.models.Sequential()\n    #model.add(keras.Input(shape=(*IMAGE_SIZE,3)))\n    model.add(keras.layers.Flatten())\n\n    model.add(keras.layers.Dense(128, activation=keras.activations.tanh,\n                                 kernel_regularizer=keras.regularizers.l2(0.01)))\n    model.add(keras.layers.Dropout(0.5))\n\n    model.add(keras.layers.Dense(64, activation=keras.activations.tanh,\n                                 kernel_regularizer=keras.regularizers.l2(0.01)))\n    model.add(keras.layers.Dropout(0.5))\n    model.add(keras.layers.Dense(32, activation=keras.activations.tanh,\n                                 kernel_regularizer=keras.regularizers.l2(0.01)))\n    model.add(keras.layers.Dropout(0.5))\n    model.add(keras.layers.Dense(16, activation=keras.activations.tanh,\n                                 kernel_regularizer=keras.regularizers.l2(0.01)))\n    model.add(keras.layers.Dropout(0.5))\n\n    model.add(keras.layers.Dense(5, activation=keras.activations.softmax,\n                                 kernel_regularizer=keras.regularizers.l2(0.001)))\n\n    model.compile(optimizer=opt, loss=loss_func, metrics=keras.metrics.categorical_accuracy)\n\n    logs = model.fit(x, y, validation_data=(val_x, val_y), epochs=epochs, batch_size=batch_size,\n                     callbacks=[keras.callbacks.LearningRateScheduler(scheduler)])\n\n    model.summary()\n\n    return logs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_conv_net(train_dataset, val_dataset, opt, loss_func, epochs, batch_size):\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n    # instantiate a distribution strategy\n    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n    # instantiating the model in the strategy scope creates the model on the TPU\n    with tpu_strategy.scope():\n        model = keras.models.Sequential()\n\n        model.add(keras.layers.Conv2D(32, (3,3), padding=\"same\", activation = 'relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n        model.add(keras.layers.Conv2D(32, (3,3), activation = 'relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n        model.add(keras.layers.BatchNormalization(axis=-1))\n        model.add(keras.layers.MaxPool2D(2,2))\n        model.add(keras.layers.Dropout(0.2))\n\n        model.add(keras.layers.Conv2D(64, (3,3), activation = 'relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n        model.add(keras.layers.BatchNormalization(axis=-1))\n        model.add(keras.layers.Conv2D(64, (3,3), activation = 'relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n        model.add(keras.layers.BatchNormalization(axis=-1))\n        model.add(keras.layers.MaxPool2D(2,2))\n        model.add(keras.layers.Dropout(0.2))\n\n        model.add(keras.layers.Conv2D(128, (3,3), activation = 'relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n        model.add(keras.layers.BatchNormalization(axis=-1))\n        model.add(keras.layers.MaxPool2D(2,2))\n        model.add(keras.layers.Dropout(0.2))\n\n        model.add(keras.layers.Flatten())\n        model.add(keras.layers.Dense(128, activation = 'relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n        model.add(keras.layers.BatchNormalization())\n        model.add(keras.layers.Dropout(0.4))\n\n        model.add(keras.layers.Dense(5, activation = 'softmax', kernel_regularizer=keras.regularizers.l2(0.001)))\n\n        model.compile(optimizer=opt, loss=loss_func, metrics=keras.metrics.categorical_accuracy)\n\n        logs = model.fit(train_dataset, validation_data=val_dataset, epochs=epochs, batch_size=batch_size,\n                        steps_per_epoch=5, validation_steps=2,\n                         callbacks=[keras.callbacks.LearningRateScheduler(scheduler)])\n    model.save(\"./output/convnet_aerial\")\n    model.summary()\n    return logs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## IV. Autres fonctions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(image):\n    print(image)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.cast(image, tf.float32)\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image\n\ndef read_tfrecord(example, labeled):\n    tfrecord_format = (\n        {\n            \"image\": tf.io.FixedLenFeature([], tf.string),\n            \"target\": tf.io.FixedLenFeature([], tf.int64),\n        }\n        if labeled\n        else {\"image\": tf.io.FixedLenFeature([], tf.string),}\n    )\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example[\"image\"])\n    if labeled:\n        label = tf.cast(example[\"target\"], tf.int32)\n        return image, label\n    return image\n\ndef load_dataset(filenames, labeled=True):\n    ignore_order = tf.data.Options()\n    ignore_order.experimental_deterministic = False  # disable order, increase speed\n    dataset = tf.data.TFRecordDataset(\n        filenames\n    )\n    # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(\n        ignore_order\n    )  # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(\n        partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE\n    )\n    return dataset\n\ndef get_dataset(filenames, labeled=True):\n    dataset = load_dataset(filenames, labeled=labeled)\n    dataset = dataset.shuffle(1024)\n    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n    dataset = dataset.batch(batch_size)\n    return dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## V. Main"},{"metadata":{"trusted":true},"cell_type":"code","source":"VALIDATION_SPLIT = 0.33\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nIMAGE_SIZE = [128, 128]\n\nepochs = 300\nbatch_size = 128\nall_logs = []\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# img = cv2.imread('./input/cassava-leaf-disease-classification/train_images/1000015157.jpg')\n# plt.figure(figsize = (10,8))\n# plt.imshow(img)\n# plt.xticks([])\n# plt.yticks([])\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialisation des datasets train et test à partir de tfrecords\n\n# train_dataset = get_dataset(training_filenames)\n# valid_dataset = get_dataset(validation_filenames)\n# test_dataset = get_dataset(TEST_FILENAMES, labeled=False)\n\n# train_csv= pd.read_csv(\"./input/train.csv\")\n# train_directory=\"./input/resize_images/\"\n#     x_train, y_train = next(iter(train_dataset))\n# x_test, y_test = next(iter(valid_dataset)\n# x_train = x_train / 255.0\n# x_test = x_test / 255.0\n# # y_train = keras.utils.to_categorical(y_train, 5)\n# # y_test = keras.utils.to_categorical(y_test, 5)\n\n# def show_batch(image_batch, label_batch):\n#     plt.figure(figsize=(20, 20))\n#     for n in range(25):\n#         ax = plt.subplot(5, 5, n + 1)\n#         plt.imshow(image_batch[n] / 255.0)\n#         plt.title(\"label : \" + str(label_batch[n]))\n#         plt.axis(\"off\")\n# show_batch(x_train.numpy(), y_train.numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv= pd.read_csv(\"../input/cassava-resize/dataset/train.csv\")\ntrain_directory=\"../input/cassava-resize/dataset/resize_images/\"\n\ntrain_datagen = keras.preprocessing.image.ImageDataGenerator(rescale= 1./255, validation_split=VALIDATION_SPLIT, shear_range= 0.2, \n        zoom_range= 0.2, horizontal_flip= True, rotation_range=20, vertical_flip= True,)\ntrain_csv[\"label\"] = train_csv[\"label\"].astype(str)\ntrain_dataset = train_datagen.flow_from_dataframe(train_csv, \n                                                    directory= train_directory, \n                                                    subset= 'training',\n                                                    x_col= 'image_id',\n                                                    y_col= 'label',\n                                                    batch_size=batch_size\n                                                   )\n\n\nvalid_dataset = train_datagen.flow_from_dataframe(train_csv,\n                                                  directory= train_directory,\n                                                  subset= 'validation',\n                                                  x_col= 'image_id',\n                                                  y_col= 'label',\n                                                  batch_size=batch_size\n                                                  )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# log = test_linear_model(train_dataset, valid_dataset, keras.optimizers.SGD(lr=0.01, momentum=0.95), keras.losses.categorical_crossentropy, epochs, batch_size)\n# all_logs.append(log)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# log = test_conv_net(x_train, y_train, x_test, y_test, keras.optimizers.SGD(lr=0.15, momentum=0.80), keras.losses.categorical_crossentropy, epochs, batch_size)\n# all_logs.append(log)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log = test_conv_net(train_dataset, valid_dataset, \"adam\", keras.losses.categorical_crossentropy, epochs, batch_size)\nall_logs.append(log)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_logs(all_logs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## X. Liens utiles\n### a. Datasets additionnels\n\n\n- Dataset d'images augmentés par images superposés fondus (clic tu comprendras c'est bon) : \nhttps://www.kaggle.com/frankmollard/2500-mixup-augmented-images\n    \n- Datasets de la compétition 2019 et 2020 fusionnés (sans duplication) : \nhttps://www.kaggle.com/tahsin/cassava-leaf-disease-merged\n\n\n### b. Notebooks intéressant\n\n\n- Etude du dataset suivi, conseils pour mener une compétition kaggle : \nhttps://www.kaggle.com/tanulsingh077/how-to-become-leaf-doctor-with-deep-learning\n    \n- Data analysis du dataset cool : \nhttps://www.kaggle.com/ihelon/cassava-leaf-disease-exploratory-data-analysis"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}